---
title: [최고의 프롬프트 엔지니어링 2.프롬프트 엔지니어링 레슨]
author: excelsiorKim
date: 2024-07-06 10:00:03 +0900
categories: [Book, PromptEngineering]
tags: [GPT, Claude3, Gemini, AI, PromptEngineering]
keywords: [GPT, Claude3, Gemini, AI, PromptEngineering]
description: 프롬프트 엔지니어링 공부 기록
toc: true
toc_sticky: true
---

# 프롬프트 엔지니어링이란
- AI로 원하는 결과를 생성하기 위해 컴퓨터와 대화하는 방법이다.
- AI를 활용하기 전에는 프로그래밍 언어를 사용해 컴퓨터와 대화했다.
- 그런데 LLM의 등장으로 이제는 우리가 일상적으로 하는 인간의 언어로도 컴퓨터에게 일을 시킬 수 있게 되었다.

## AI 시대 새로운 코딩, 프롬프트 엔지니어링
- **프롬프트 엔지니어링의 가장 기본적인 원칙** : 질문을 잘할수록 좋은 대답을 얻는다.
  - 특히 컴퓨터는 훨씬 더 정확하게 명령을 내려야 원하는 결과를 얻을 수 있다.
  - 이것이 프로그래밍 언어에서는 코딩이고, 생성형 AI에서는 프롬프트 엔지니어링이다.

## 프롬프트 엔지니어링의 가장 대표적인 다섯 가지 방법
### 제로샷 프롬프팅
- Zero-shot 프롬프팅은 LLM에게 아무런 데이터나 예시를 주지 않고도 바로 특정 작업을 수행하도록 지시하는 것이다.
- 예시
  - "이 문장을 한국어로 번역해 줘"라고 말하면 LLM은 사전 훈련된 지식만으로 번역을 시도하는 것이다.

### 원샷 러닝
- LLM에게 명령을 내릴 때 실행 방법에 대한 예시 한 개를 동시에 제공한다.
- 예시
  - "영어를 한국어로 번역해줘" 라고 작업 지시를 내리는 동시에 "This is an apple을 한국어로 번역하면 '이것은 사과입니다'야"라는 예시를 제공하는 것이다.
- 마치 AI에게 작은 단어를 하나 주는 것과 같다

### 퓨샷 러닝
- 퓨샷 러닝은 마치 조리법을 배울 때 여러 가지 예시를 참고하는 것 처럼, LLM에게 특정 명령을 내릴 때 2~3개부터 수십 개 정도의 에시와 함께 제공한다.
- 이로 인해 AI는 명령을 더 정확하게 이해하고 수행한다.
- 따라서 퓨샷 러닝은 데이터가 부족하거나 특정 작업에 대한 사례가 많지 않을 때 특히 유용하다.
- AI는 제공된 몇 가지 에시를 분석하여 일반적인 패턴이나 규칙을 추출하고, 이를 바탕으로 더 넓은 범위의 작업을 수행할 수 있기 대문이다.
- 이는 마치 인간이 새로운 상황을 만났을 때 과거 경험에서 얻은 지식을 바탕으로 판단하고 행동하는 방식과 유사하다.

### CoT(Chain of Thought)
- 이 방법은 마치 복잡한 수학 문제를 풀기 위해 문제를 쪼개어 단계적으로 푸는 것과 유사하다.
- LLM에게 문제 해결 과정에서 따라야 할 생각의 단계나 논리적 순서를 제시하면 LLM은 이 사고 과정을 따라 문제를 분석하고 각 단계를 거치면서 최종 해답에 도달한다.
- CoT 접근 방식의 핵심은 AI가 단순히 결과를 도출하는 것이 아니라 문제 해결 과정에 필요한 논리적 사고를 모방하도록 하는 것이다.
- 이는 AI가 단순히 지식을 암기하고 적용하는 것을 넘어 문제를 해석하고 주어진 해결책을 사용하는 등 '생각'하는 방법을 배우게 한다.
- CoT는 특히 복잡한 문제 해결과 추론을 요구하는 작업에 유용하며, AI의 이해력과 추론 능력을 크게 향상 시킬 수 있다.

### 제로샷 CoT
- 기존 CoT와 비슷한 방식이지만 문제 해결 과정에서 따라야 할 생각의 단계나 논리적 순서 등의 가이드를 주지 않는다.
- 그 대신 해결할 문제를 주고 그저 천천히 생각해 보라는 식으로만 지시한다.
- LLM은 그러면 스스로 문제를 분석하고 사고 과정을 작성해 가면서 자신의 사고 과정에 따라 해답을 도출한다.

## 기본적인 프롬프트 구성
- 프롬프트 엔지니어링은 실험적인 방법론에 기반하기 때문에 한 번 그럴 듯한 결과를 내고 끝내는 것이 아니라 원하는 결과를 정확히 의도한 대로, 항상 일ㄹ관되게 만드는 것이 목표이다.
- 우리가 보통 ChatGPT를 사용할 때 한 번 질문하고 답변을 받으면 그만이기 때문에 시중에 돌아다니는 프롬프트 템플릿을 받아 사용하는 것만으로도 충분할 수 있다. 
- 그러나 이러한 방법은 프롬프트 엔지니어링이 아니라 블라인드 프롬프팅(blind prompting) 혹은 프롬프트 라이팅(prompt writing)이라고 한다.
  - 결과에 대한 설계와 평가가 없어 결과의 일관성과 정확성을 보장할 수 없기 때문이다.
- 따라서 본격적인 서비스나 애플리케이션을 만드려면 사람들이 원하는 기능을 다각도로 살펴보고, 원하는 결과를 의도한 대로 일관성 있게 내기 위한 충분한 설계와 실험이 필요하다.

<br>

- **기본적인 프롬프트의 구성**
  1. 답변을 위해 필요한 적절한 컨텍스트 제공
     - 먼저 답변에 필요한 정보인 컨텍스트를 제공한다.
     - 예를 들어 AI가 답변해야 하는 정보와 관련된 내용을 컨텍스트로 제공한다.
     - 이때 컨텍스트는 보통 정제되지 않은 긴 텍스트로 제공한다.
     - 이를 통해 할루시네이션이 없는 더 정확한 응답을 생성할 수 있다.
  2. 원하는 결과 추출을 위한 프롬프트 작성
     - 구체적으로 원하는 결과를 얻기 위한 지시를 한다.
  3. 결과물의 형식을 지정
     - 마지막으로 정보의 가독성과 처리 용이성을 위해 답변의 형식을 지정한다.

<br>

- 중요한 것은 사용자가 답변을 얻기 위해 사전에 어떤 문맥, 즉 어떤 컨텍스트를 제공하느냐이다.
- 이 컨텍스트는 LLM이 질문을 이해하고 그에 맞는 답변을 생성하는데 필수적이다.
- 따라서 사용자는 질문의 배경, 관련 정보, 원하는 답변의 세부 사항을 명확히 제시함으로써 더 정확하고 관련성 높은 답변을 얻을 수 있다.

<br>

- 프롬프트는 그 자체가 프로그램이 될 수도 있다.
- 프로그램이 데이터와 알고리즘 두 가지로 구성되어 있듯이, 프롬프트도 컨텍스트와 사용자가 지시하는 인스트럭션(instruction)이 합쳐진 것이다.

### Bing Chat과 ChatGPT의 차이
- ChatGPT는 프롬프트로 요청을 하면 바로 답변을 생성하기 때문에 제대로 된 정보를 제공할 수 없는 반면, Bing Chat은 진짜 이런 사건이 있었는지 웹에서 검색한 결과를 LLM에 전달한다.
- 이렇게 양질의 답변을 위해 적절한 컨텍스트를 제공하고 활용하는 것을 인 컨텍스트 러닝이라고 한다.
- ChatGPT와 BingChat의 차이는 이 인컨텍스트 러닝의 유무이다.

# 컨텍스트를 가져오는 기술 - 벡터 서치
- LLM 애플리케이션은 프롬프트를 잘 만드는 것도 중요하지만 사용자의 요청에 알맞는 정보를 잘 찾아 제시하는 것도 매우 중요하다.
- 그런데 이 정보를 찾아오는 것 역시 LLM을 통해 가능해졌다.

## LLM의 숨은 영웅, 임베딩
- LLM으로 정보를 찾는 과정을 이해하려면 임베딩(Embedding)을 알아야 한다.
  - LLM에서 임베딩이란 단어나 문장 같은 언어의 조각들을 숫자로 바꾸는 과정을 말한다.
- 임베딩에 의해 변환된 숫자들은 숫자의 집합, 벡터 형태를 가지며, 이 숫자의 집합은 단어나 문장같은 언어 조각들의 개념적 위치를 알려주는 역할을 한다.
  - 예를 들어 '사과'라는 단어는 [0.1, 0.2], '바나나'라는 단어는 [0.3, 0.4]라는 벡터로 변환된다.
  - 이런 벡터 값에 의해 '사과'나 '바나나'는 다른 단어이지만숫자로 표현된 공간에서 서로 가까운 위치에 있다는 것을 알 수 있다.
  - 또한 컴퓨터는 두 단어 모두 '과일'이라는 범주에 있는 것을 포착하여 해당 단어를 더 잘 이해할 수 있다.
- 텍스트를 숫자로 바꾸는 머신러닝 모델을 임베딩 모델이라고 한다.
  - 임베딩 모델은 대량의 텍스트 데이터를 분석하여 각 단어나 문장이 가진 의미와 문맥을 숫자 벡터로 표현한다.
    - 이러한 과정을 벡터화라고 하며, 이렇게 변환된 숫자의 집합이 바로 임베딩 벡터이다.
    - 참고로, LLM 모델이 실제로 받아들이는 데이터는 이렇게 벡터화된 데이터이다.
- 생성된 벡터를 고차원으로 표현할수록 단어 간의 복잡한 관계를 더 정밀하게 표현할 수 있다.

## 벡터 서치와 시맨틱 서치
- 지금까지 단어 간의 관계를 3차원으로 표현하는 것까지 살펴봤다. 그런데 OpenAI에서 내놓은 임베딩 벡터는 무려 1,000 차원이 넘는다.
  - 이러한 고차원 벡터는 인간이 볼 수 없는 수준이지만 그만큼 단어의 특징은 잘 표현한다고 볼 수 있다.
- 그리고 n차원의 임베딩 공간에서 가까운 단어를 찾는 것이 벡터 서치이다.
  - 가까움의 기준 : 거리 또는 유사도
- 이러한 백터 서치는 단어의 의미를 기반으로 검색한다고 해서 시맨틱 서치라고도 한다.
- **단어 뿐만 아니라 문장도 임베딩이 가능하다.**
- 키워드 기반의 전통적인 검색 엔진은 검색의 정확도와 속도를 높이기 위해 입력된 텍스트에서 불필요한 문제들을 제거하고 단어를 기본형태로 변형하는 형태소 분석, 유사어 및 다국어 처리 등과 같은 복잡한 과정을 거쳐야 했다.
- 반면, 벡터 서치를 사용하면 이러한 전처리 과정을 거치지 않아도 의미나 맥락까지 고려한 유사 정보를 쉽게 찾아낼 수 있다.
- 또한 의미 기반으로 검색하기 때문에 검색의 정확도와 성능 또한 크게 향상 시킬 수 있어 자연어 처리(NLP), 이미지 검색, 추천 시스템 등 다양한 LLM에 널리 사용되고 있다.

## 백터 서치의 명암
- 벡터 서치는 전통적인 검색 엔진처럼 복잡한 시스템을 필요로 하지 않는다.
- 따라서 누구나 쉽고 빠르게 고성능의 검색 엔진을 구축할 수 있게 됐다.
- 이러한 검색 엔진과 LLM을 통해 개인화된 답변을 출력하는 작업도 매우 쉬워진 데다가, 언어와 관계 없이 질문과 답변을 만들 수 있으니 전 세계 사람들을 대상으로한 개인화된 백과 사전을 만드는 것이 너무나 간단해졌다.
### 단점
- **속도 문제**
  - 수십만개의 포인트로된 벡터를 연산하는데는 속도 문제가 발생할 수 있다.
- **성능 문제**
  - 처리 속도를 높이기 위해 만들어진 여러 알고리즘 중 하나인 ANN 알고리즘은 정확도는 약간 떨어지는 대신 빠르게 유사한 벡터를 찾을 수있는 기술이다.
  - 해당 알고리즘의 핵심 작동원리는 고차원 데이터 공간을 더 작은 공간으로 '근사화'하는 것이다.
  - 이를 통해 ANN 알고리즘은 데이터 포인트 간의 완벽한 거리 계산을 피하고, 대신 근사값을 사용하여 빠른 검색을 수행한다.
  - ANN의 작동 원리 중 '차원 축소'기법이라는 것이 있다.
    - 데이터의 차원을 줄여 계산 복잡도를 줄이는 동시에 원본 데이터의 중요한 특성을 유지하려고 시도한다.
    - 이를 해결하기 위해 하이브리드 서치라는 방식을 사용하기도 한다.
      - 먼저 키워드 검색을 통해 DB에서 후보 데이터 일부를 검색해 온 다음, 사용자가 요청한 내용과 유사한 데이터를 벡터 서치로 다시 한 번 필터링하는 방식이다.
        - 혹은 반대 과정을 거치기도 함.

### 결론
- AI가 생성하는 답변의 질은 AI에게 제공한 데이터, 즉 컨텍스트의 질과 이를 얼마나 잘 활용하게 만드느냐에 달려있다.